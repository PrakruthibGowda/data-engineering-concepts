## Extract and Load

<p align='centre'> 
Extract Load is the simplest and most staright-forward data integration methodology.
</p>

### Extract 
* Data is pulled from source systems
* Sources - Common sources can be Relational databases, Logs, APIs, Stream data from kafka etc 
* Methods - Data can be extracted in full, incrementally or in real time.

### Load 
* Data is loaded directly into the target system
* Targets - Common targets could be a Datawarehouse like BigQuery, Snowflake or be a Datalake like S3 buckets, Azure Delta lakes or GCS buckets. It can also be a Lakehouse like Databricks or Delta Lake.
* Stratergies - Loading also can be either done in batches, streams of real or near real-time, append only or using upserts to insert new data and update existing data. 

### Transform 
* Happens after loading data into target if or when needed.
* If transformation is needed immediately after data lands in storage layer, it becomes a ELT pipeline not an EL.
* EL pipelines are those where the data is ready to be pulled to your Datawarehouse and deos not require transformations and it is available to be consumed by business logic or analytics.

#### Example : Revenue dashboard
You have a relational DB say MSSQl to handle OLTP data from your e-commerce website. marketing team needs this data for Revenue dashboards. All that is needed in this situation is a simple extract of the data from MSSQL table and load it into your datawarehouse like Bigquery for analytics.

MSSQL (orders table)
        -->
Python Script
        -->
BigQuery (analytics.orders_raw)

